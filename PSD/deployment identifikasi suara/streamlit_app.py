import streamlit as st
import numpy as np
import pandas as pd
import librosa
import librosa.display
import scipy.stats as stats
from scipy import signal
import soundfile as sf
import joblib
import io
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import multiprocessing
warnings.filterwarnings('ignore')

# Performance Configuration
N_JOBS = max(1, multiprocessing.cpu_count() - 1)
FAST_MODE = True  # Use optimized feature set for faster processing

# Konfigurasi halaman
st.set_page_config(
    page_title="Voice Recognition: Buka/Tutup",
    page_icon="üé§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Judul aplikasi
st.title("Sistem Identifikasi Suara: Buka/Tutup")
st.markdown("---")
st.markdown("**Aplikasi untuk mengklasifikasi suara 'buka' dan 'tutup' menggunakan Machine Learning**")

# Fungsi ekstraksi features dengan optimasi
@st.cache_data
def extract_statistical_features(audio_data, sr=22050, fast_mode=True):
    """
    Ekstraksi berbagai feature statistik dari sinyal audio time series
    fast_mode: True = 28 features (optimized), False = 61 features (complete)
    """
    features = {}
    
    # 1. Basic Statistical Features (always included)
    features['mean'] = np.mean(audio_data)
    features['std'] = np.std(audio_data)
    features['var'] = np.var(audio_data)
    features['median'] = np.median(audio_data)
    features['min'] = np.min(audio_data)
    features['max'] = np.max(audio_data)
    features['range'] = features['max'] - features['min']
    
    # 2. Percentile Features (always included)
    features['q25'] = np.percentile(audio_data, 25)
    features['q75'] = np.percentile(audio_data, 75)
    features['iqr'] = features['q75'] - features['q25']
    
    # 3. Distribution Shape Features (always included)
    features['skewness'] = stats.skew(audio_data)
    features['kurtosis'] = stats.kurtosis(audio_data)
    
    # 4. Energy and Power Features (always included)
    features['energy'] = np.sum(audio_data**2)
    features['power'] = features['energy'] / len(audio_data)
    features['rms'] = np.sqrt(np.mean(audio_data**2))
    
    # 5. Zero Crossing Rate (always included)
    features['zcr'] = np.sum(librosa.zero_crossings(audio_data))
    features['zcr_rate'] = features['zcr'] / len(audio_data)
    
    if fast_mode:
        # Fast mode: Only essential features (28 features total)
        
        # 6. Basic Spectral Features (3 features)
        try:
            features['spectral_centroid'] = np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sr))
            features['spectral_rolloff'] = np.mean(librosa.feature.spectral_rolloff(y=audio_data, sr=sr))
            features['zcr_mean'] = np.mean(librosa.feature.zero_crossing_rate(audio_data))
        except:
            features['spectral_centroid'] = 0
            features['spectral_rolloff'] = 0
            features['zcr_mean'] = 0
        
        # 7. Basic MFCC Features (6 features - first 3 MFCCs only)
        try:
            mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=3)
            for i in range(3):
                features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])
                features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])
        except:
            for i in range(3):
                features[f'mfcc_{i+1}_mean'] = 0
                features[f'mfcc_{i+1}_std'] = 0
        
        # 8. Basic Envelope Features (3 features)
        try:
            envelope = np.abs(signal.hilbert(audio_data))
            features['envelope_mean'] = np.mean(envelope)
            features['envelope_std'] = np.std(envelope)
            features['envelope_max'] = np.max(envelope)
        except:
            features['envelope_mean'] = 0
            features['envelope_std'] = 0
            features['envelope_max'] = 0
    
    else:
        # Complete mode: All features (61 features total)
        
        # 6. Complete Spectral Features
        try:
            features['spectral_centroid'] = np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sr))
            features['spectral_bandwidth'] = np.mean(librosa.feature.spectral_bandwidth(y=audio_data, sr=sr))
            features['spectral_rolloff'] = np.mean(librosa.feature.spectral_rolloff(y=audio_data, sr=sr))
        except:
            features['spectral_centroid'] = 0
            features['spectral_bandwidth'] = 0
            features['spectral_rolloff'] = 0
        
        # 7. Temporal Features
        try:
            onset_frames = librosa.onset.onset_detect(y=audio_data, sr=sr)
            features['onset_count'] = len(onset_frames)
            tempo = librosa.beat.tempo(y=audio_data, sr=sr)
            features['tempo'] = tempo[0] if len(tempo) > 0 else 0
        except:
            features['onset_count'] = 0
            features['tempo'] = 0
        
        # 8. Autocorrelation Features
        autocorr = np.correlate(audio_data, audio_data, mode='full')
        autocorr = autocorr[autocorr.size // 2:]
        if len(autocorr) > 100:
            features['autocorr_max'] = np.max(autocorr[1:100])
            features['autocorr_mean'] = np.mean(autocorr[1:100])
        else:
            features['autocorr_max'] = np.max(autocorr[1:]) if len(autocorr) > 1 else 0
            features['autocorr_mean'] = np.mean(autocorr[1:]) if len(autocorr) > 1 else 0
        
        # 9. Complete Envelope Features
        try:
            envelope = np.abs(signal.hilbert(audio_data))
            features['envelope_mean'] = np.mean(envelope)
            features['envelope_std'] = np.std(envelope)
            features['envelope_max'] = np.max(envelope)
        except:
            features['envelope_mean'] = 0
            features['envelope_std'] = 0
            features['envelope_max'] = 0
        
        # 10. Complete MFCC Statistical Features
        try:
            mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
            for i in range(13):
                features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])
                features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])
        except:
            for i in range(13):
                features[f'mfcc_{i+1}_mean'] = 0
                features[f'mfcc_{i+1}_std'] = 0
        
        # 11. Chroma Features
        try:
            chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)
            features['chroma_mean'] = np.mean(chroma)
            features['chroma_std'] = np.std(chroma)
        except:
            features['chroma_mean'] = 0
            features['chroma_std'] = 0
        
        # 12. Contrast Features
        try:
            contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sr)
            features['contrast_mean'] = np.mean(contrast)
            features['contrast_std'] = np.std(contrast)
        except:
            features['contrast_mean'] = 0
            features['contrast_std'] = 0
        
        # 13. Tonnetz Features
        try:
            tonnetz = librosa.feature.tonnetz(y=audio_data, sr=sr)
            features['tonnetz_mean'] = np.mean(tonnetz)
            features['tonnetz_std'] = np.std(tonnetz)
        except:
            features['tonnetz_mean'] = 0
            features['tonnetz_std'] = 0
    
        # 14. Attack Time (only in complete mode)
        peak_idx = np.argmax(np.abs(audio_data))
        features['attack_time'] = peak_idx / sr
        
        # 15. Decay Rate (only in complete mode)
        if peak_idx < len(audio_data) - 1:
            decay_signal = audio_data[peak_idx:]
            if len(decay_signal) > 1:
                features['decay_rate'] = np.mean(np.diff(decay_signal))
            else:
                features['decay_rate'] = 0
        else:
            features['decay_rate'] = 0
    
    return features

# Fungsi preprocessing audio
def preprocess_audio(audio_data, sr, noise_threshold=0.01):
    """Preprocess audio: noise removal, trimming"""
    try:
        audio_trimmed, _ = librosa.effects.trim(audio_data, top_db=20)
    except:
        audio_trimmed = audio_data
    
    audio_denoised = np.where(np.abs(audio_trimmed) < noise_threshold, 0, audio_trimmed)
    return audio_denoised

# Fungsi load model
@st.cache_resource
def load_model():
    """Load model pipeline"""
    try:
        pipeline = joblib.load('voice_classifier_pipeline.pkl')
        return pipeline
    except FileNotFoundError:
        st.error("Model file 'voice_classifier_pipeline.pkl' tidak ditemukan!")
        st.info("Pastikan Anda telah menjalankan notebook training terlebih dahulu.")
        return None

# Fungsi prediksi dengan optimasi
def predict_audio_class(audio_data, pipeline, sr=22050):
    """Prediksi kelas untuk audio baru dengan optimasi performance"""
    if pipeline is None:
        return None, None, None
    
    try:
        # Ekstraksi features dengan fast mode
        features = extract_statistical_features(audio_data, sr=sr, fast_mode=FAST_MODE)
        
        # Convert ke DataFrame dan pilih features yang sama
        features_df = pd.DataFrame([features])
        
        # Check if all required features exist
        required_features = pipeline['feature_names']
        missing_features = [f for f in required_features if f not in features_df.columns]
        
        if missing_features:
            # Add missing features with default value 0
            for feature in missing_features:
                features_df[feature] = 0
        
        features_selected = features_df[required_features]
        
        # Replace inf values
        features_selected = features_selected.replace([np.inf, -np.inf], np.nan)
        features_selected = features_selected.fillna(0)
        
        # Scale features
        features_scaled = pipeline['scaler'].transform(features_selected)
        
        # Prediksi
        prediction_encoded = pipeline['model'].predict(features_scaled)[0]
        prediction = pipeline['label_encoder'].inverse_transform([prediction_encoded])[0]
        
        # Probabilitas
        if hasattr(pipeline['model'], 'predict_proba'):
            probabilities = pipeline['model'].predict_proba(features_scaled)[0]
            confidence = np.max(probabilities)
        else:
            confidence = 1.0
        
        return prediction, confidence, features
    except Exception as e:
        st.error(f"Error dalam prediksi: {str(e)}")
        return None, None, None

# Load model
pipeline = load_model()

if pipeline is not None:
    # Sidebar - Model Information
    st.sidebar.header("Informasi Model")
    st.sidebar.write(f"**Model Type**: {pipeline['model_info']['model_type']}")
    st.sidebar.write(f"**Features**: {pipeline['model_info']['n_features']}")
    st.sidebar.write(f"**Classes**: {', '.join(pipeline['model_info']['classes'])}")
    
    # Main interface
    st.header("Upload Audio File")
    
    uploaded_file = st.file_uploader(
        "Pilih file audio (.wav, .mp3, .m4a)", 
        type=['wav', 'mp3', 'm4a'],
        help="Upload file audio yang ingin diklasifikasi"
    )
    
    if uploaded_file is not None:
        # Load audio
        try:
            # Read audio file
            audio_data, sr = librosa.load(uploaded_file, sr=22050, duration=5)
            
            # Preprocess
            audio_processed = preprocess_audio(audio_data, sr)
            
            # Display audio info
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Informasi Audio")
                st.write(f"**Durasi**: {len(audio_data)/sr:.2f} detik")
                st.write(f"**Sample Rate**: {sr} Hz")
                st.write(f"**Jumlah Sample**: {len(audio_data)}")
                st.write(f"**Range Nilai**: [{audio_data.min():.4f}, {audio_data.max():.4f}]")
                
                # Play audio
                st.audio(uploaded_file)
            
            with col2:
                st.subheader("Visualisasi Waveform")
                fig, ax = plt.subplots(figsize=(10, 4))
                time_axis = np.linspace(0, len(audio_data)/sr, len(audio_data))
                ax.plot(time_axis, audio_data)
                ax.set_xlabel('Waktu (detik)')
                ax.set_ylabel('Amplitudo')
                ax.set_title('Waveform Audio')
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
            
            # Prediksi
            st.subheader("Hasil Prediksi")
            
            if st.button("üéØ Klasifikasi Audio", type="primary"):
                with st.spinner("Memproses audio..."):
                    prediction, confidence, features = predict_audio_class(audio_processed, pipeline)
                
                if prediction is not None:
                    # Display hasil prediksi
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric(
                            label="Prediksi Kelas",
                            value=prediction.upper(),
                            help="Hasil klasifikasi audio"
                        )
                    
                    with col2:
                        st.metric(
                            label="Confidence Score",
                            value=f"{confidence:.2%}",
                            help="Tingkat kepercayaan model"
                        )
                    
                    with col3:
                        status = "‚úÖ TINGGI" if confidence > 0.8 else "‚ö†Ô∏è SEDANG" if confidence > 0.6 else "‚ùå RENDAH"
                        st.metric(
                            label="Status Confidence",
                            value=status,
                            help="Interpretasi tingkat kepercayaan"
                        )
                    
                    # Progress bar untuk confidence
                    st.progress(confidence)
                    
                    # Feature analysis (optional)
                    with st.expander("üìä Analisis Features (Advanced)"):
                        if features:
                            features_df = pd.DataFrame([features]).T
                            features_df.columns = ['Nilai']
                            
                            # Top features
                            st.subheader("Top 10 Features")
                            top_features = pipeline['feature_names'][:10]
                            top_values = [features.get(f, 0) for f in top_features]
                            
                            fig, ax = plt.subplots(figsize=(10, 6))
                            ax.barh(top_features, top_values)
                            ax.set_xlabel('Nilai Feature')
                            ax.set_title('Top 10 Features yang Digunakan Model')
                            plt.tight_layout()
                            st.pyplot(fig)
                            
                            # Feature statistics
                            st.subheader("Statistik Features")
                            selected_features = ['mean', 'std', 'zcr_rate', 'spectral_centroid', 'energy']
                            stats_data = {f: features.get(f, 0) for f in selected_features if f in features}
                            
                            if stats_data:
                                stats_df = pd.DataFrame([stats_data])
                                st.dataframe(stats_df, use_container_width=True)
        
        except Exception as e:
            st.error(f"Error loading audio file: {str(e)}")
            st.info("Pastikan file audio dalam format yang didukung (WAV, MP3, M4A)")

# Sidebar - Performance & Info
st.sidebar.markdown("---")
st.sidebar.header("‚ö° Performance Settings")

# Performance indicators
feature_count = 28 if FAST_MODE else 61
st.sidebar.metric(
    label="Feature Extraction Mode",
    value="FAST" if FAST_MODE else "COMPLETE",
    delta=f"{feature_count} features"
)

st.sidebar.metric(
    label="Parallel Processing",
    value=f"{N_JOBS} cores",
    delta="Optimized"
)

processing_time = "~0.1-0.3s" if FAST_MODE else "~0.5-1.0s"
st.sidebar.metric(
    label="Estimated Processing Time",
    value=processing_time,
    delta="per audio"
)

st.sidebar.markdown("---")
st.sidebar.header("üìã Tentang Aplikasi")
st.sidebar.markdown(f"""
**Voice Recognition System**

Aplikasi ini menggunakan:
- **{feature_count} Statistical Features** dari time series audio
- **Random Forest Classifier** untuk klasifikasi
- **Parallel Processing** untuk optimasi speed
- **Feature Caching** untuk performa

**Optimasi Yang Diterapkan:**
- ‚úÖ Fast Mode Feature Extraction ({feature_count} features)
- ‚úÖ Multi-core Processing ({N_JOBS} cores)
- ‚úÖ Streamlit Caching untuk model loading
- ‚úÖ Efficient audio preprocessing

**Cara Penggunaan:**
1. Upload file audio (.wav/.mp3/.m4a)
2. Klik tombol 'Klasifikasi Audio'
3. Lihat hasil prediksi dan confidence score

**Supported Classes:**
- üîì Buka
- üîí Tutup
""")

st.sidebar.markdown("---")
st.sidebar.success(f"Sistem siap! Mode: {'FAST' if FAST_MODE else 'COMPLETE'}")
st.sidebar.info("Dikembangkan untuk Proyek PSD - Voice Classification")